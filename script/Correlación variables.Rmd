---
title: "Correlación variables"
author: "Claudia Tribaldos"
date: "`r Sys.Date()`"
output: html_document
editor_options: 
  chunk_output_type: console
---

# Librerías 
```{r}
library(here)
library(readxl)
library(terra)
```

# Convertr los raster a dataframe

prueba con 1 
```{r}
dfprueba<- terra::as.data.frame(raster_list$CLI_TMNI, xy=TRUE, na.rm=TRUE) # xy= TRUE significa que las coordenadas de cada raster se calculan y se incluyen 
# na.rm = TRUE para que los valores de mi raster que sean NA se borren 
```

crear stack y dataframe
```{r}
files <- list.files(pattern='\\.tiff$', full=TRUE, path=here::here("data/variablesexpl"))

variablesexpl <- rast(files) # esto ya sería el stack 

df <- terra::as.data.frame(variablesexpl, xy=TRUE, na.rm=TRUE)
```

# Matriz de correlación
```{r}
matriz_cor <- cor(df[,3:38]) #hazme la correlación de todo el df menos la columna 1 y la 2 
```

# Cor.mtest

declarando una función: cor.mtest (modificada). correlación + p valores de cada correlación 
```{r}
cor.mtest <- function(mat, ...) {
    mat <- as.matrix(mat)
    n <- ncol(mat)
    p.mat<- matrix(NA, n, n)
    diag(p.mat) <- 0
    for (i in 1:(n - 1)) {
        for (j in (i + 1):n) {
            tmp <- cor.test(mat[, i], mat[, j], ...)
            p.mat[i, j] <- p.mat[j, i] <- tmp$p.value
        }
    }
  colnames(p.mat) <- rownames(p.mat) <- colnames(mat)
  p.mat
}
```

# P valor de cada correlación 

```{r}
p.mat <- cor.mtest(df[,3:38]) # sacar los p valores de cada correlación con la función de arriba

# hacer el plot chulo
library(corrplot)
plot1 <- corrplot::corrplot(matriz_cor, type = "upper", tl.col = "black", tl.srt = 90, tl.cex = 0.4,
         p.mat = p.mat, sig.level = 0.05, 
         insig = "blank", 
         diag = FALSE)

# posible argumento a añadir: order. Me ordena las variables según 3 posibles métodos: FPC (análisis de componentes principales), AOE, hclust. 
# nos interesa bastante el FPC pero tb el hclust 
# hclust -> me ordena las variables según los diferentes grupos de variables que se correlacionan más entre sí y luego me dibuja los rectángulos alrededor 


plot2 <- corrplot::corrplot(matriz_cor, type = "upper", tl.col = "black", tl.srt = 90, tl.cex = 0.4,
         p.mat = p.mat, sig.level = 0.05, 
         insig = "blank", 
         diag = FALSE, 
         order ="hclust", 
         addrect= 5, 
         hclust.method = "ward.D")

#plot con PCA 

plot3 <- corrplot::corrplot(matriz_cor, type = "upper", tl.col = "black", tl.srt = 90, 
         tl.cex = 0.4,
         p.mat = p.mat, 
         sig.level = 0.05, 
         insig = "blank", 
         diag = FALSE, 
         order ="FPC")
```


# Cluster 

Hierarchical cluster

## Nº óptimo de clusters
```{r}
install.packages("cluster")
library(factoextra)

smalldf <- df[sample(1:5000),,drop=FALSE] # he tomado una muestra de la dataframe porque era demasiado grande para la función nb clust 

fviz_nbclust(smalldf, kmeans, method = "gap_stat", nboot = 50)

fviz_nbclust(smalldf, hcut, method = "gap_stat", nboot = 100)

fviz_nbclust(smalldf, clara, method = "gap_stat", nboot = 100)

# con todos los métodos me sale que el nº óptimo de clusters es 1???
```

 

```{r}
h <- hcut(smalldf, k=3)
dendro <- fviz_dend(h, rect = TRUE, horiz = TRUE, lwd = 0.5, cex = .5)
dendro
ggsave(here::here("figs/dendrograma_env.pdf"), 
       height = 7, width = 5, device = "pdf")
```

# análisis de ordenación

voy a hacer un filtrado de las variables ambientales por análisis de componentes principales (PCA)

Es una técnica estadística de síntesis de la información, o reducción de la dimensión (número de variables)

Es decir, ante un banco de datos con muchas variables, el objetivo será reducirlas a un menor número perdiendo la menor cantidad de información posible.

Si quiero que todas las especies tengan la misma importancia, lo que hago es que las *estandarizar* (Varianza=1, media=0). Si estamos haciendo un PCA para conocer los ejes que explican las variables ambientales, siempre tengo que estandarizar, porque las unidades son diferentes.

Lo que hacemos en un PCA es buscar los ejes que me expliquen la mayor variabilidad según el número de variables.

##Cuando NO podemos hacer el PCA

-   Cuando la relación entre la abndancia de las especies con respecto a un gradiente ambiental no es lineal
-   Cuando los ejes del PCP no recogen de forma fiable la variablidad

###CA (Análisis de correspondencia)

Usamos este tipo de análisis cuando la relación entre la abundancia de las especies con respecto a un gradiente ambiental no es lineal, sino unimodal. El funcionamiento de este análisis es idéntico al del PCA, con ejes etc.

Longitud de los ejes

En función de la longitud de los ejes DCA decido si la relación entre las variables son lineales o unimodales. - *Longitud \< 3 = relación lineal (PCA)* - *Longitud \> 4 = relación unimodal (CA)* - *Longitud 3-4 = sin preferencias*


```{r}
library(vegan)
df$x<-NULL
df$y<-NULL

dfstand<- decostand(df, "standardize")
vare.pca<-rda(dfstand)
summary(vare.pca)
plot(vare.pca, display="species")
```